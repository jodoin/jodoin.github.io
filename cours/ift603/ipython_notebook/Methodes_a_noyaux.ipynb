{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Régression logistique à noyau\n",
    "\n",
    "Avec ce code, vous verrez comment une régression logistique linéaire utilisant les colonnes d'une matrice de Gram peut devenir une excellent classifieur non linéaire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as pypl\n",
    "\n",
    "##\n",
    "# Régression logistique à noyau (entraîné par descente de gradient stochastique)\n",
    "##\n",
    "\n",
    "# Génération des données d'entraînement\n",
    "# (X_1,t_1) et (X_2,t_2) sont les données de 2 classes différentes\n",
    "X_1_1 = 0.5*np.random.randn(5,2) + np.array([[5,1]]) # Gaussienne centrée en mu_1_1=[5,1]\n",
    "X_1_2 = 0.5*np.random.randn(5,2) + np.array([[0,4]]) # Gaussienne centrée en mu_1_1=[0,4]\n",
    "X_1 = np.vstack([X_1_1,X_1_2])\n",
    "t_1 = np.ones(10)\n",
    "X_2 = 0.5*np.random.randn(10,2) + np.array([[2,3]]) # Gaussienne centrée en mu_2=[2,3]\n",
    "t_2 = np.zeros(10)\n",
    "\n",
    "# Fusionne toutes les données dans un seul ensemble d'entraînement\n",
    "X = np.vstack([X_1,X_2])\n",
    "t = np.hstack([t_1,t_2])\n",
    "#Mélange dans un ordre aléatoire\n",
    "p = np.random.permutation(20)     \n",
    "X = X[p,:]\n",
    "t = t[p]\n",
    "\n",
    "# Hyper-paramètre du noyau gaussien\n",
    "sigma_2 = 0.5 \n",
    "\n",
    "# Noyau gaussien\n",
    "def k(x,x_prime):\n",
    "      return np.exp(-np.dot(x-x_prime,x-x_prime)/(2*sigma_2))\n",
    "\n",
    "# Fonction sigmoid\n",
    "def sigm(a):\n",
    "    return 1./(1. + np.exp(-a))\n",
    "    \n",
    "# Pour visualiser le classifieur\n",
    "delta = 0.025\n",
    "ix = np.arange(-2.0, 7.0, delta)\n",
    "iy = np.arange(-1.0, 6.0, delta)\n",
    "iX, iY = np.meshgrid(ix, iy)\n",
    "X_vis = np.hstack([iX.reshape((-1,1)),iY.reshape((-1,1))])\n",
    "\n",
    "# Initialisation du classifieur de la régression logistique\n",
    "w = np.zeros((20,))\n",
    "w_0 = 0.\n",
    "eta = 0.5 # Normalement, on utiliserait une valeur plus petite\n",
    "\n",
    "# Pré-calcul de la matrice de Gram\n",
    "K = np.array([[k(x,x_prime) for x_prime in X] for x in X])\n",
    "\n",
    "# Pré-calcul de la matrice comparant X_vis à X\n",
    "K_vis = np.array([[k(x,x_prime) for x_prime in X_vis] for x in X])\n",
    "\n",
    "# Descente de gradient stochastique\n",
    "pypl.subplots(figsize=(20,20))\n",
    "for it in range(1):\n",
    "    for n in range(X.shape[0]):\n",
    "        # Calcul p(C_1 | x_n) en prenant la n-ième colonne de K au lieu de x_n \n",
    "        o = sigm(w_0 + np.dot(K[n,:],w))\n",
    "        \n",
    "        # Calcul les gradients de w et w_0\n",
    "        grad_w = o-t[n]\n",
    "        grad_w_0 = sum(o-t[n:n+1])\n",
    "\n",
    "        # Mise à jour des paramètres\n",
    "        w[n] -= eta * grad_w\n",
    "        w_0 -= eta * grad_w_0\n",
    "        \n",
    "        # Visualisation\n",
    "        pypl.subplot(5,4,1+n)\n",
    "        dummy = pypl.scatter(X_1[:,0],X_1[:,1])\n",
    "        dummy = pypl.scatter(X_2[:,0],X_2[:,1],marker='+')\n",
    "        dummy = pypl.scatter(X[n,0],X[n,1],c='r',s=50.)\n",
    "\n",
    "        contour_out = sigm(np.dot(K_vis.T,w)+w_0).reshape(iX.shape)\n",
    "        dummy = pypl.contour(iX,iY,contour_out,colors='k')\n",
    "        pypl.clabel(dummy, inline=1, fontsize=10)\n",
    "        \n",
    "\n",
    "pypl.imshow(np.flipud(contour_out))\n",
    "pypl.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
